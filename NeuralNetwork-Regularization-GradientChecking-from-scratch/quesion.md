Question 01 [50 marks] :
Implement a neural network and utilize the CIFAR-10 dataset for the analysis.
1. Utilize various activation functions like sigmoid, tanh and critique the performance in
each case.
2. Increase the depth of the given network by adding more Fully-Connected layers till the
point you encounter the vanishing gradient problem. With the help of the results, mention
how to identify it.
3. Suggest and implement methods to overcome the above problem.

   
Question 02 [50 marks] :


Implement a neural network on the Gurmukhi dataset and implement the following regularization
techniques from scratch:
1. L-1 regularization
2. L-2 regularization

3. Dropout
Compare the performance of the above techniques and mention reasons to support your
answer. You are free to utilize PyTorch's inbuilt functions for implementing activation and loss
functions. However, various regularization techniques must be implemented from scratch
without the support of any library.
Also, implement gradient checking (from scratch) to verify the values of gradients during
backpropagation.
(refer to this hint for gradient checking)
