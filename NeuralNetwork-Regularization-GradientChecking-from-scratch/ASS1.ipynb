{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Dz73jlfiOVpq",
        "wGFsC5K0HP9Y",
        "YE9dLZF2keLO",
        "yKP0XNTivoVy",
        "eUq4ny2_T0Xn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5059eb8101334d0182bb3fb192a5b513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f49cde53bd0741d7bc37a9831023ef00",
              "IPY_MODEL_888a43014ce54db18f02dd6685b78d4d"
            ],
            "layout": "IPY_MODEL_f4f1725d3189415984a3ce81f223ad03"
          }
        },
        "f49cde53bd0741d7bc37a9831023ef00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_661a1e65b16b4412bec5db7127ed92b5",
            "placeholder": "​",
            "style": "IPY_MODEL_8af8e11426a14212a27522ba9b56ca7e",
            "value": "0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "888a43014ce54db18f02dd6685b78d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c67c27a1d24bcfbf8117e5dd314541",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c1ad971ae274eaa912b96bf380bcd0a",
            "value": 0.09489216799091942
          }
        },
        "f4f1725d3189415984a3ce81f223ad03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661a1e65b16b4412bec5db7127ed92b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af8e11426a14212a27522ba9b56ca7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23c67c27a1d24bcfbf8117e5dd314541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1ad971ae274eaa912b96bf380bcd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebfedbaea17f4e8f889a033905b26436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30604df6b3b64215be4c6617cba3ca9c",
              "IPY_MODEL_58924ed099b74e729bdfecc06c8f9fc7",
              "IPY_MODEL_871bd884aa55495c9d08c210d01eeb6c"
            ],
            "layout": "IPY_MODEL_2f8c8dd189ef446c8310c73be0d4dc8c"
          }
        },
        "30604df6b3b64215be4c6617cba3ca9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72322a72a824b81a38b0c95f76ccc0b",
            "placeholder": "​",
            "style": "IPY_MODEL_03ba2b10203f4017af6b401f44a17127",
            "value": "100%"
          }
        },
        "58924ed099b74e729bdfecc06c8f9fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ca638f365c47fa983ddba05afb7492",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dd32e6476db430bab670ace10ee5c45",
            "value": 170498071
          }
        },
        "871bd884aa55495c9d08c210d01eeb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bbccdf67e694a898ade5188ebd02c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_7824077139a744df957bde9dca5a0985",
            "value": " 170498071/170498071 [00:03&lt;00:00, 45905438.53it/s]"
          }
        },
        "2f8c8dd189ef446c8310c73be0d4dc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72322a72a824b81a38b0c95f76ccc0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ba2b10203f4017af6b401f44a17127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ca638f365c47fa983ddba05afb7492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd32e6476db430bab670ace10ee5c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bbccdf67e694a898ade5188ebd02c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7824077139a744df957bde9dca5a0985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93e73e334a4040a0a311b0bda5ae4790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_085cce3e518e4264bc11c796f611254d",
              "IPY_MODEL_fdf5e519473b47e69f49a4da25db0756"
            ],
            "layout": "IPY_MODEL_5d95acfb7d4f414d86882cf4200f8327"
          }
        },
        "085cce3e518e4264bc11c796f611254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8478e52d07b2470680f54103c4257671",
            "placeholder": "​",
            "style": "IPY_MODEL_42fe7bcc5e544ec5ac335822da04a0cf",
            "value": "0.001 MB of 0.037 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "fdf5e519473b47e69f49a4da25db0756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f402551d2342d8b29e85e6ff76eb31",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba2d94721f194a1da03c8dae3e4428e8",
            "value": 0.017472909213459842
          }
        },
        "5d95acfb7d4f414d86882cf4200f8327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8478e52d07b2470680f54103c4257671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42fe7bcc5e544ec5ac335822da04a0cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f402551d2342d8b29e85e6ff76eb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2d94721f194a1da03c8dae3e4428e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a76e06544b7e451ca077a3fd78559975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_118c55fcb01140b6bba38172c511cb1b",
              "IPY_MODEL_6d54107f17804841a8f5ae0c2ab45182"
            ],
            "layout": "IPY_MODEL_837174d9a0d444509d346f56855b4924"
          }
        },
        "118c55fcb01140b6bba38172c511cb1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db2b5328f01545fc88ca0471aeb36e18",
            "placeholder": "​",
            "style": "IPY_MODEL_88e035bf9a1143c8b27d50f53cfe452d",
            "value": "0.001 MB of 0.051 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6d54107f17804841a8f5ae0c2ab45182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c504907bcf744eb989d2545305f10a7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98347cb410674b48b1eb15138377259c",
            "value": 0.012654430925554452
          }
        },
        "837174d9a0d444509d346f56855b4924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db2b5328f01545fc88ca0471aeb36e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e035bf9a1143c8b27d50f53cfe452d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c504907bcf744eb989d2545305f10a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98347cb410674b48b1eb15138377259c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d4faba9bab944f18f32d38740dffce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f2caf08d7534ef08003433f260c6e29",
              "IPY_MODEL_43fc93ca1e224ec9b3b155a60a3067a0"
            ],
            "layout": "IPY_MODEL_fe6882a987dc4b98ab83d0510fc812a6"
          }
        },
        "9f2caf08d7534ef08003433f260c6e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5938e2a51e07495091371ffd72366105",
            "placeholder": "​",
            "style": "IPY_MODEL_ad152f417ccb4a34ac04bc2cc32bf265",
            "value": "0.001 MB of 0.056 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "43fc93ca1e224ec9b3b155a60a3067a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26ef57f456e4973aff3cda57c220e0c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ae6492eca5d49a68032c5bccd037b65",
            "value": 0.012691858595772765
          }
        },
        "fe6882a987dc4b98ab83d0510fc812a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5938e2a51e07495091371ffd72366105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad152f417ccb4a34ac04bc2cc32bf265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e26ef57f456e4973aff3cda57c220e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae6492eca5d49a68032c5bccd037b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b8949d43e684de38e4280e827d538b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa54f7792e2a4b88872001b213cbda19",
              "IPY_MODEL_5de68a49568b46b1b76f6585a4fb4c17"
            ],
            "layout": "IPY_MODEL_e3dc8334135c43ba9bb01f4119dd3d2f"
          }
        },
        "aa54f7792e2a4b88872001b213cbda19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_499aed913f4a412bbe2ac37c5d4ecd95",
            "placeholder": "​",
            "style": "IPY_MODEL_b0b94c37b31a42209286d94def9ed27b",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5de68a49568b46b1b76f6585a4fb4c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a937e154544bea8bc4dde6221acdff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bda7f3eb35d4d81973d4137cb32b2ad",
            "value": 1
          }
        },
        "e3dc8334135c43ba9bb01f4119dd3d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499aed913f4a412bbe2ac37c5d4ecd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b94c37b31a42209286d94def9ed27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8a937e154544bea8bc4dde6221acdff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bda7f3eb35d4d81973d4137cb32b2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ceb2d607b694fc1b45fa8b342668807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d049fb6f00504be2ba34d75adb60d611",
              "IPY_MODEL_27ac3205f6cf4c989f9f973e09476e39"
            ],
            "layout": "IPY_MODEL_856a20bd941d4aa0b1ad81787aa7d20e"
          }
        },
        "d049fb6f00504be2ba34d75adb60d611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74dcb95d94834e6b9363f9262f239057",
            "placeholder": "​",
            "style": "IPY_MODEL_d0dc59ac4aee4d2080ab3d762d46059d",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "27ac3205f6cf4c989f9f973e09476e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb289de8ea44f48a6c0229d58f1e04e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e9935b6b8e244079580fa0d50a6cc8f",
            "value": 1
          }
        },
        "856a20bd941d4aa0b1ad81787aa7d20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74dcb95d94834e6b9363f9262f239057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dc59ac4aee4d2080ab3d762d46059d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb289de8ea44f48a6c0229d58f1e04e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9935b6b8e244079580fa0d50a6cc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d67e4130b3a1445b8d272164d7b9a477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14df141ee3b040108151d43d1396ce5f",
              "IPY_MODEL_255db6b71f2b4fa4a8be0ffffc9c180b"
            ],
            "layout": "IPY_MODEL_fbf99131b7cc4ece921edf9c3b8663bb"
          }
        },
        "14df141ee3b040108151d43d1396ce5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f06edaa25f64c22b5dc1fefb296f157",
            "placeholder": "​",
            "style": "IPY_MODEL_13ac30958b0e444ba1452c6df9b83ce9",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "255db6b71f2b4fa4a8be0ffffc9c180b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b60603ff754468585ddd3ee742df32b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96d8bab3aaae4335bbc5d70671ac0d11",
            "value": 1
          }
        },
        "fbf99131b7cc4ece921edf9c3b8663bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f06edaa25f64c22b5dc1fefb296f157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ac30958b0e444ba1452c6df9b83ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b60603ff754468585ddd3ee742df32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d8bab3aaae4335bbc5d70671ac0d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q1\n",
        "Implement a neural network and utilize the CIFAR-10 dataset for the analysis.\n",
        "1. Utilize various activation functions like sigmoid, tanh and critique the performance in\n",
        "each case.\n",
        "2. Increase the depth of the given network by adding more Fully-Connected layers till the\n",
        "point you encounter the vanishing gradient problem. With the help of the results, mention\n",
        "how to identify it.\n",
        "3. Suggest and implement methods to overcome the above problem."
      ],
      "metadata": {
        "id": "C4bZryXPHAag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        " \n",
        "# Sigmoid one layer\n",
        "\n"
      ],
      "metadata": {
        "id": "wGFsC5K0HP9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IGNIV_4qOaFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def gradient_check_n(model, X, Y, epsilon=1e-7):\n",
        "\n",
        "   \n",
        "    parameters_values = dictionary_to_vector(model)\n",
        "    grad = gradients_to_vector(model)\n",
        "    num_parameters = parameters_values.shape[0]\n",
        "    J_plus = np.zeros((num_parameters, 1))\n",
        "    J_minus = np.zeros((num_parameters, 1))\n",
        "    gradapprox = np.zeros((num_parameters, 1))\n",
        "    \n",
        "    \n",
        "    for i in range(num_parameters):\n",
        "        \n",
        "        \n",
        "        thetaplus =  np.copy(parameters_values)                                       # Step 1\n",
        "        thetaplus[i][0] = thetaplus[i][0] + epsilon                                   # Step 2\n",
        "        J_plus[i] =  forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))  # Step 3\n",
        "        \n",
        "        thetaminus = np.copy(parameters_values)                                       # Step 1\n",
        "        thetaminus[i][0] = thetaminus[i][0] - epsilon                                 # Step 2        \n",
        "        J_minus[i] = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus)) # Step 3\n",
        "        \n",
        "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
        "       \n",
        "    \n",
        "    \n",
        "    numerator = np.linalg.norm(grad - gradapprox)                                     # Step 1'\n",
        "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   # Step 2'\n",
        "    difference = numerator / denominator                                              # Step 3'\n",
        "    \n",
        "    truth=0\n",
        "    if difference > 1e-7:\n",
        "        truth=1\n",
        "   \n",
        "    return truth"
      ],
      "metadata": {
        "id": "kS6n3LlLfE8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "0f28qQeFOmnp",
        "outputId": "cae7ca1e-f341-451c-c6d0-63c1075f057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"sigmoid1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "MuwDOiBZNxH6",
        "outputId": "4a5189bc-b436-49b1-e7a7-722c31d796cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msharma-87\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_122611-es3u7fqq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/sigmoid1/runs/es3u7fqq\" target=\"_blank\">legendary-rabbit-4</a></strong> to <a href=\"https://wandb.ai/sharma-87/sigmoid1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/sigmoid1\" target=\"_blank\">https://wandb.ai/sharma-87/sigmoid1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/sigmoid1/runs/es3u7fqq\" target=\"_blank\">https://wandb.ai/sharma-87/sigmoid1/runs/es3u7fqq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/sigmoid1/runs/es3u7fqq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0d484f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb.config"
      ],
      "metadata": {
        "id": "0w-S8bVaOe3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "FQG33OZLN1Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "ebfedbaea17f4e8f889a033905b26436",
            "30604df6b3b64215be4c6617cba3ca9c",
            "58924ed099b74e729bdfecc06c8f9fc7",
            "871bd884aa55495c9d08c210d01eeb6c",
            "2f8c8dd189ef446c8310c73be0d4dc8c",
            "f72322a72a824b81a38b0c95f76ccc0b",
            "03ba2b10203f4017af6b401f44a17127",
            "a5ca638f365c47fa983ddba05afb7492",
            "6dd32e6476db430bab670ace10ee5c45",
            "7bbccdf67e694a898ade5188ebd02c2d",
            "7824077139a744df957bde9dca5a0985"
          ]
        },
        "id": "P3vY7SsqMOM6",
        "outputId": "a4cfa901-89ed-4b6f-ff9e-5448b4d56af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to path/to/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebfedbaea17f4e8f889a033905b26436"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting path/to/data/cifar-10-python.tar.gz to path/to/data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_dataset):\n",
        "    inputs, labels = data\n",
        "   # print('Labels:', labels)\n",
        "    print('Labels:', inputs.shape)\n",
        "    if i == 2: # only show the first 3 data points\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmP_G1Byvulz",
        "outputId": "114c8e1e-21d3-48e7-c293-9107c6c584b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: torch.Size([1, 32, 32])\n",
            "Labels: torch.Size([1, 32, 32])\n",
            "Labels: torch.Size([1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = sig(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "from torch import optim\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gxdHailHMcoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYdYQ9NUOwXg",
        "outputId": "42600dd2-e5a5-4890-845c-70d3bfb0a003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "Kn9TKtZVO6bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(7):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        loss = criterion(output, target.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()"
      ],
      "metadata": {
        "id": "BMrSMTlvPS7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data.to(device))\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target.to(device)).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FaTzH0vRXpw",
        "outputId": "f202065c-834d-4a16-9395-d3151b5d3498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 37.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "93e73e334a4040a0a311b0bda5ae4790",
            "085cce3e518e4264bc11c796f611254d",
            "fdf5e519473b47e69f49a4da25db0756",
            "5d95acfb7d4f414d86882cf4200f8327",
            "8478e52d07b2470680f54103c4257671",
            "42fe7bcc5e544ec5ac335822da04a0cf",
            "96f402551d2342d8b29e85e6ff76eb31",
            "ba2d94721f194a1da03c8dae3e4428e8"
          ]
        },
        "id": "I_qyKUvkRkQI",
        "outputId": "6b2cb0a6-e4a4-4c84-9d0e-f8e845640e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93e73e334a4040a0a311b0bda5ae4790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██████</td></tr><tr><td>loss</td><td>█▆▄▄▄▅▅▄▃▅▃▄▇▆▅▁▂▅▃▃▅▃▂▁▂▃▇▁▄▃▅▅▄▁▃▃▂▂▃▃</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>1.68155</td></tr><tr><td>test_accuracy</td><td>0.3751</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">legendary-rabbit-4</strong> at: <a href=\"https://wandb.ai/sharma-87/sigmoid1/runs/es3u7fqq\" target=\"_blank\">https://wandb.ai/sharma-87/sigmoid1/runs/es3u7fqq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_122611-es3u7fqq/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.cpu().detach().requires_grad_(requires_grad=True)"
      ],
      "metadata": {
        "id": "M4TQelbcS1SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_check_n(model, inputs, labels, epsilon=1e-7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjOzFZr2cw0j",
        "outputId": "517e2637-945d-422a-ae27-0ef5ea5d684c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid 2 hidden layer \n"
      ],
      "metadata": {
        "id": "rqxLggF5qMvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bJYvI5dYqMvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"sig2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bcd9173-d699-4706-c6b4-cb6216597e37",
        "id": "Y3l_a21sqMvj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb\n",
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "cCZ85V3nqMvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca02c56-56e9-402e-e9c6-124c4e250b4b",
        "id": "Kbm1apdmqMvk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "relu=torch.nn.ReLU()\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = sig(self.fc1(x))\n",
        "        x = sig(self.fc2(x))\n",
        "        x=sig(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "C5LoG_PlqMvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")\n",
        "\n",
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        loss = criterion(output, target.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "V4SYCHB_qMvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data.to(device))\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target.to(device)).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    #wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244e799b-d8b5-4532-c0d9-32ffab8e7389",
        "id": "PhfOwPT9qMvl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 35.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR8Rua5DW55u",
        "outputId": "fef42e7d-7276-49f6-9cb2-a9c9d8661073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
              "         ...,\n",
              "         [0.4588, 0.4510, 0.4275,  ..., 0.3059, 0.3020, 0.3020],\n",
              "         [0.4510, 0.4235, 0.4039,  ..., 0.2863, 0.2902, 0.3216],\n",
              "         [0.4314, 0.4039, 0.3882,  ..., 0.3255, 0.3255, 0.3294]]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_check_n(model, inputs, labels, epsilon=1e-7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPOqDHo2WQB-",
        "outputId": "f81d263e-60b9-488b-a0c1-5d10a1605288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Model accuracy:\", evaluate_model(model, test_loader))\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "vnacq8lFzcZ6",
        "outputId": "df7e8c1d-27d3-4371-ee63-f23de3aefec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss</td><td>▇▇█▅▆▅▅▅▇▄▃▆▄▅▅▄▅▅▄▂▃▄▄▁▃▂▃▄▄▄▅▄▄▅▄▄▃▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>1.93492</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glittering-springroll-4</strong> at: <a href=\"https://wandb.ai/sharma-87/sig2/runs/4blbjxiz\" target=\"_blank\">https://wandb.ai/sharma-87/sig2/runs/4blbjxiz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_124109-4blbjxiz/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OPEzbSeyqMvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid 3 hidden layer \n"
      ],
      "metadata": {
        "id": "TCz3wpGdC8pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "C_HvwQHGC8pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"sigmoid3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "bb2e45a6-6eee-40c1-cc58-58c6b4add3c6",
        "id": "NRi7BD8sC8pj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_124350-rbd893q3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/sigmoid3/runs/rbd893q3\" target=\"_blank\">auspicious-lantern-6</a></strong> to <a href=\"https://wandb.ai/sharma-87/sigmoid3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/sigmoid3\" target=\"_blank\">https://wandb.ai/sharma-87/sigmoid3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/sigmoid3/runs/rbd893q3\" target=\"_blank\">https://wandb.ai/sharma-87/sigmoid3/runs/rbd893q3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/sigmoid3/runs/rbd893q3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0d2cdcf40>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb\n",
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=128,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "h8WAeWg7C8pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d629355-bd3f-46d0-b4ec-181489691256",
        "id": "FKEar4t6C8pk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "relu=torch.nn.ReLU()\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = sig(self.fc1(x))\n",
        "        x = sig(self.fc2(x))\n",
        "        x = sig(self.fc3(x))\n",
        "        x=sig(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "WAZrLSx8C8pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")\n",
        "\n",
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(7):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data=data.to(device)\n",
        "        output = model(data)\n",
        "        target=target.to(device)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "xF8Y5wXVC8pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data=data.to(device)\n",
        "            target=target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    #wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99830f23-2671-4112-cc4b-9fba2c1bdb04",
        "id": "EtlQxXzOC8pl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 24.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_check_n(model, inputs, labels, epsilon=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuntsac6gUYI",
        "outputId": "812eea88-d6ef-4c06-8597-75d9c947324f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308,
          "referenced_widgets": [
            "a76e06544b7e451ca077a3fd78559975",
            "118c55fcb01140b6bba38172c511cb1b",
            "6d54107f17804841a8f5ae0c2ab45182",
            "837174d9a0d444509d346f56855b4924",
            "db2b5328f01545fc88ca0471aeb36e18",
            "88e035bf9a1143c8b27d50f53cfe452d",
            "0c504907bcf744eb989d2545305f10a7",
            "98347cb410674b48b1eb15138377259c"
          ]
        },
        "outputId": "a4578627-0345-4db4-f3b7-5e37be34c472",
        "id": "nsj5y5tkC8pl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 24.59\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.051 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.012654…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a76e06544b7e451ca077a3fd78559975"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██████</td></tr><tr><td>loss</td><td>█▇▇▄▆▅▅▅▄▅▄▄▅▂▅█▄▃▄▄▃▅▃▅▁▃▅▃▃▅▃▅▂▄▃▁▃▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>2.06783</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">auspicious-lantern-6</strong> at: <a href=\"https://wandb.ai/sharma-87/sigmoid3/runs/rbd893q3\" target=\"_blank\">https://wandb.ai/sharma-87/sigmoid3/runs/rbd893q3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_124350-rbd893q3/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BDOHr2s_C8pm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRBd6kdimDGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        " \n",
        "# Tanh one layer\n",
        "\n"
      ],
      "metadata": {
        "id": "tZK48Wna78Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "YVBiHsdB78Gn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce53b93b-5511-4c0b-e1dd-d83486b9ffe1",
        "id": "S-d5qk5C78Gn"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Tanh1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1a7987c5-c501-48c6-c15e-889c3273d029",
        "id": "8FrGYhO378Gn"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_134137-5o90xtep</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/Tanh1/runs/5o90xtep\" target=\"_blank\">red-wish-4</a></strong> to <a href=\"https://wandb.ai/sharma-87/Tanh1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/Tanh1\" target=\"_blank\">https://wandb.ai/sharma-87/Tanh1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/Tanh1/runs/5o90xtep\" target=\"_blank\">https://wandb.ai/sharma-87/Tanh1/runs/5o90xtep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/Tanh1/runs/5o90xtep?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0d2dfebb0>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb.config"
      ],
      "metadata": {
        "id": "1Af7YEAi78Go"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=128,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "NFXZG5Yt78Go"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755c2a7b-67ae-4f39-e3b0-49290bc05fd5",
        "id": "1hrqe7rd78Go"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_dataset):\n",
        "    inputs, labels = data\n",
        "   # print('Labels:', labels)\n",
        "    print('Labels:', inputs.shape)\n",
        "    if i == 2: # only show the first 3 data points\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa90391f-5193-42dd-8e92-433cb08b2a9a",
        "id": "teNQGUw578Go"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: torch.Size([1, 32, 32])\n",
            "Labels: torch.Size([1, 32, 32])\n",
            "Labels: torch.Size([1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "t=torch.nn.Tanh()\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = t(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "4aHd_2EF78Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5f9f45-1e61-4f03-b83d-8f2fff1d7339",
        "id": "fsQ6Qiqb78Go"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "n5ZF_cWJ78Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        loss = criterion(output, target.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()"
      ],
      "metadata": {
        "id": "i2EreDn_78Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data.to(device))\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            target=target.to(device)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec52924-a6fe-447a-e847-fbb23d79cd90",
        "id": "zX9BP2V078Go"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 35.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "8b8949d43e684de38e4280e827d538b0",
            "aa54f7792e2a4b88872001b213cbda19",
            "5de68a49568b46b1b76f6585a4fb4c17",
            "e3dc8334135c43ba9bb01f4119dd3d2f",
            "499aed913f4a412bbe2ac37c5d4ecd95",
            "b0b94c37b31a42209286d94def9ed27b",
            "b8a937e154544bea8bc4dde6221acdff",
            "6bda7f3eb35d4d81973d4137cb32b2ad"
          ]
        },
        "outputId": "d2748649-749c-4a1d-ff5d-c3c6c329ed67",
        "id": "UXUM4CtF78Go"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b8949d43e684de38e4280e827d538b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">red-wish-4</strong> at: <a href=\"https://wandb.ai/sharma-87/Tanh1/runs/5o90xtep\" target=\"_blank\">https://wandb.ai/sharma-87/Tanh1/runs/5o90xtep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_134137-5o90xtep/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relu one hidden layer \n"
      ],
      "metadata": {
        "id": "YE9dLZF2keLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "id": "8YQVqDMmmSAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CHnVQ8UJkiwI"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"Relu1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "BuHLUdqikoV4",
        "outputId": "ce35d019-9bcf-4f23-c597-b992c809018d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_134239-51mxg2f5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/Relu1/runs/51mxg2f5\" target=\"_blank\">cheerful-dog-1</a></strong> to <a href=\"https://wandb.ai/sharma-87/Relu1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/Relu1\" target=\"_blank\">https://wandb.ai/sharma-87/Relu1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/Relu1/runs/51mxg2f5\" target=\"_blank\">https://wandb.ai/sharma-87/Relu1/runs/51mxg2f5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/Relu1/runs/51mxg2f5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0d2b891c0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb\n",
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=128,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "vLFtOycPkybM"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtZPxUTmk9Yg",
        "outputId": "228544a1-969b-4ca6-888c-f2642ae5f316"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "relu=torch.nn.ReLU()\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "NPLxliowlBVD"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")\n",
        "\n",
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "V9JUnp1AlQNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n",
        "print(gradient_check_n(model, inputs, labels, epsilon=1e-5))\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "0ceb2d607b694fc1b45fa8b342668807",
            "d049fb6f00504be2ba34d75adb60d611",
            "27ac3205f6cf4c989f9f973e09476e39",
            "856a20bd941d4aa0b1ad81787aa7d20e",
            "74dcb95d94834e6b9363f9262f239057",
            "d0dc59ac4aee4d2080ab3d762d46059d",
            "3fb289de8ea44f48a6c0229d58f1e04e",
            "0e9935b6b8e244079580fa0d50a6cc8f"
          ]
        },
        "id": "ICH6bCiJlkGA",
        "outputId": "0d372d3e-5d71-483a-ecd5-296a06d3721f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 37.82\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ceb2d607b694fc1b45fa8b342668807"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss</td><td>▆▆█▆▄█▆▆▅▄▃▄▄▁▄▄▃▃▂▆▅▆▄▄▄▄▄▄▃▅▄▂▁█▄▂▃▂▂▇</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>1.91879</td></tr><tr><td>test_accuracy</td><td>0.3782</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cheerful-dog-1</strong> at: <a href=\"https://wandb.ai/sharma-87/Relu1/runs/51mxg2f5\" target=\"_blank\">https://wandb.ai/sharma-87/Relu1/runs/51mxg2f5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_134239-51mxg2f5/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUmblw4f6z9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✌\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bTsSUBKDpefo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relu 2 hidden layer \n"
      ],
      "metadata": {
        "id": "yKP0XNTivoVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "id": "eoXXzU1qvoVz"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "EBQsCwu0voVz"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"Vanishing gradient\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "413640b1-4a67-4516-861b-a8d30328626d",
        "id": "HOlaZrv_voVz"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_134710-iiyde08k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/Vanishing%20gradient/runs/iiyde08k\" target=\"_blank\">lucky-ox-13</a></strong> to <a href=\"https://wandb.ai/sharma-87/Vanishing%20gradient\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/Vanishing%20gradient\" target=\"_blank\">https://wandb.ai/sharma-87/Vanishing%20gradient</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/Vanishing%20gradient/runs/iiyde08k\" target=\"_blank\">https://wandb.ai/sharma-87/Vanishing%20gradient/runs/iiyde08k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/Vanishing%20gradient/runs/iiyde08k?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0d2c15970>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb\n",
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=128,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "ckSImj5KvoV0"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f84d66-8915-49ec-894d-cb8fae5e44ac",
        "id": "MTLAmDYQvoV0"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "relu=torch.nn.ReLU()\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = relu(self.fc1(x))\n",
        "        x = relu(self.fc2(x))\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "IKojJItwvoV0"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")\n",
        "\n",
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        loss = criterion(output, target.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "HAhAeaMXvoV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n",
        "print(gradient_check_n(model, inputs, labels, epsilon=1e-5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d383233-3719-4496-ab91-5d5384e9ddad",
        "id": "9JXwHiYtvoV0"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 39.86\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "ODwkp_QX7ju4",
        "outputId": "91abfc66-ffa0-49c1-c6dd-2824eb290d2a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>loss</td><td>██▆▆▇▄▅▆▅▆▆▃▄▂▄▆▃▅▃▄▄▃▄▃▄▅▂▃▁▃▄▃▃▃▃▆▁▅▃▂</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>1.58406</td></tr><tr><td>test_accuracy</td><td>0.3986</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lucky-ox-13</strong> at: <a href=\"https://wandb.ai/sharma-87/Vanishing%20gradient/runs/iiyde08k\" target=\"_blank\">https://wandb.ai/sharma-87/Vanishing%20gradient/runs/iiyde08k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_134710-iiyde08k/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✌\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lNZinfrsvoV1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLVGTSnZC8PW"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relu 3 hidden layer \n"
      ],
      "metadata": {
        "id": "3o28buLlvche"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3625ce-50b5-4026-ae3f-a21f962f89c3",
        "id": "L2VrVFlIvchf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "q9BkAvi_vchg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"ReLu3hiddenlayer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "7934308c-a2d1-4eaa-9aef-17252f9653f7",
        "id": "MySJChCgvchg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_084856-epe68tlc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/ReLu3hiddenlayer/runs/epe68tlc\" target=\"_blank\">legendary-wish-4</a></strong> to <a href=\"https://wandb.ai/sharma-87/ReLu3hiddenlayer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/ReLu3hiddenlayer\" target=\"_blank\">https://wandb.ai/sharma-87/ReLu3hiddenlayer</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/ReLu3hiddenlayer/runs/epe68tlc\" target=\"_blank\">https://wandb.ai/sharma-87/ReLu3hiddenlayer/runs/epe68tlc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/ReLu3hiddenlayer/runs/epe68tlc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f906bccdc10>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb\n",
        "config = dict(\n",
        "    epochs=10,\n",
        "    classes=10,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.001,\n",
        "    dataset=\"CFIAR\",\n",
        "    architecture=\"MLP\")"
      ],
      "metadata": {
        "id": "BGeFEdytvchg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='path/to/data', train=True,\n",
        "                                download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='path/to/data', train=False,\n",
        "                               download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fc05c7-7198-457c-dec2-476f54ba09a8",
        "id": "EcTaMetnvchg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "sig=torch.nn.Sigmoid()\n",
        "relu=torch.nn.ReLU()\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = relu(self.fc1(x))\n",
        "        x = relu(self.fc2(x))\n",
        "        x = relu(self.fc3(x))\n",
        "        x=self.fc4(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "OGzDThNZvchh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")\n",
        "\n",
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data=data.to(device)\n",
        "        output = model(data)\n",
        "        target=target.to(device)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "bVXb-NBDvchh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data=data.to(device)\n",
        "            target=target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    #wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49a4408-84ab-49a5-e86b-3a53d0c5ee00",
        "id": "Wo9kq8Mxvchh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 38.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308,
          "referenced_widgets": [
            "1d4faba9bab944f18f32d38740dffce1",
            "9f2caf08d7534ef08003433f260c6e29",
            "43fc93ca1e224ec9b3b155a60a3067a0",
            "fe6882a987dc4b98ab83d0510fc812a6",
            "5938e2a51e07495091371ffd72366105",
            "ad152f417ccb4a34ac04bc2cc32bf265",
            "e26ef57f456e4973aff3cda57c220e0c",
            "1ae6492eca5d49a68032c5bccd037b65"
          ]
        },
        "outputId": "151fe14e-edad-491d-e462-714235eb4487",
        "id": "Ok2z91zevchh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 37.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d4faba9bab944f18f32d38740dffce1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss</td><td>█▇▅▃▆▃▆▆▂▂▃▄▄▂▆▅▄▆▄▃▅▅▃▂▁▅▂▂▅▄▄▂▃▁▂▃▄▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>1.75149</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">legendary-wish-4</strong> at: <a href=\"https://wandb.ai/sharma-87/ReLu3hiddenlayer/runs/epe68tlc\" target=\"_blank\">https://wandb.ai/sharma-87/ReLu3hiddenlayer/runs/epe68tlc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_084856-epe68tlc/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7CGauPVovchi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lToeFeNxvchi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2"
      ],
      "metadata": {
        "id": "Y3bDFgvsmDew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a neural network on the Gurmukhi dataset and implement the following regularization\n",
        "techniques from scratch:\n",
        "1. L-1 regularization\n",
        "2. L-2 regularization\n",
        "3. Dropout\n",
        "\n",
        "Compare the performance of the above techniques and mention reasons to support your\n",
        "answer. You are free to utilize PyTorch's inbuilt functions for implementing activation and loss\n",
        "functions. However, various regularization techniques must be implemented from scratch\n",
        "without the support of any library.\n",
        "Also, implement gradient checking (from scratch) to verify the values of gradients during\n",
        "backpropagation."
      ],
      "metadata": {
        "id": "Qr5EKCgFmMGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L1\n"
      ],
      "metadata": {
        "id": "UV70BMcyTtCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijSpkvIRnyaw",
        "outputId": "0ed7445d-e0a5-405b-e65b-7c1ef29c1506"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.img_paths = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for label in os.listdir(root_dir):\n",
        "            label_dir = os.path.join(root_dir, label)\n",
        "            if not os.path.isdir(label_dir):\n",
        "                continue\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                self.img_paths.append(img_path)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = int(self.labels[idx])\n",
        "        return img, label\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7EmPzcasfXo"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyVQls3UlTk9",
        "outputId": "c5aa2c9c-8c40-4ea2-f04b-96ab08bf53ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2aLN2bulScm",
        "outputId": "ec43badb-b600-4054-9daf-e65f4dfb6b5c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"gurnumL1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "nnKfDaT9lyV_",
        "outputId": "3938b6ca-0b97-4ca2-dc6a-7594c8c39cce"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_135850-vsgqhr30</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/gurnumL1/runs/vsgqhr30\" target=\"_blank\">festive-rabbit-6</a></strong> to <a href=\"https://wandb.ai/sharma-87/gurnumL1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/gurnumL1\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/gurnumL1/runs/vsgqhr30\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL1/runs/vsgqhr30</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/gurnumL1/runs/vsgqhr30?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0d2ae4310>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "E8cPy5xcywW-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                ])\n",
        "\n",
        "train_dataset = ImageDataset(root_dir='/content/drive/MyDrive/GurNum/train', transform=transform)\n",
        "test_dataset = ImageDataset(root_dir='/content/drive/MyDrive/GurNum/val', transform=transform)\n"
      ],
      "metadata": {
        "id": "SwK1H18ipRG4"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "y7FvAqKSpxSw"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_dataset):\n",
        "    inputs, labels = data\n",
        "    print(data)\n",
        "    \n",
        "    if i == 2: # only show the first 3 data points\n",
        "        break"
      ],
      "metadata": {
        "id": "-BrHP8TpqC_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb24a75d-0645-461b-d3c1-cb06d930ab43"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n",
            "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n",
            "(tensor([[[1., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        # self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=1*32*32, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jsirszE2yZLR"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "blSGnkIzxoOz"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzrrW2kMmE8N",
        "outputId": "461d11a1-7cc2-4bc7-8a02-1aa45512b378"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "IU24PSvamSpx"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l1_loss(model, weight_decay):\n",
        "    l1_loss = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'bias' not in name:\n",
        "            l1_loss += torch.sum(torch.abs(param))\n",
        "    return weight_decay * l1_loss"
      ],
      "metadata": {
        "id": "QL8IoZD40VMt"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".1 , 5"
      ],
      "metadata": {
        "id": "dXggBrSDAL7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        target=torch.tensor(target)\n",
        "        reg_loss = l1_loss(model, 0.000001)\n",
        "        loss = criterion(output, target.to(device)) +reg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n",
        "    print(\"for epoch \",epoch, \" loss= \",running_loss)   "
      ],
      "metadata": {
        "id": "58tKBJ2BwfVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data=data.to(device)\n",
        "            target=target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    #wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb273Gx0yCIe",
        "outputId": "dfe3f6e2-f7ee-42df-f3d3-cd712e605f2d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 92.13483146067416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# l1 grad\n"
      ],
      "metadata": {
        "id": "IbC53RcABvz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dictionary_to_vector(model):\n",
        "  \n",
        "    params = list(model.parameters())\n",
        "    p=[]\n",
        "    for param in params:\n",
        "      p.append(param.cpu().detach().numpy())\n",
        "     \n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(p)):\n",
        "  \n",
        "  \n",
        "        new_vector = np.reshape(p[i], (-1,1))\n",
        "        \n",
        "        \n",
        "        if count == 0:\n",
        "            theta = new_vector\n",
        "        else:\n",
        "            theta = np.concatenate((theta, new_vector), axis=0)\n",
        "        count = count + 1\n",
        "\n",
        "    return theta"
      ],
      "metadata": {
        "id": "ErkE1QtQBv0A"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradients_to_vector(model):\n",
        "    \n",
        "    theta = np.reshape(model.fc1.weight.grad.cpu().detach().numpy(), (-1,1))\n",
        "    theta1=np.concatenate((theta,np.reshape( model.fc1.bias.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "    theta2=np.concatenate((theta1, np.reshape(model.fc2.weight.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "    theta3=np.concatenate((theta2, np.reshape(model.fc2.bias.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "\n",
        "    return theta3"
      ],
      "metadata": {
        "id": "C-dcsZmwBv0A"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_to_dictionary(theta):\n",
        "    \n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = theta[:131072].reshape(128, 1024)\n",
        "    parameters[\"b1\"] = theta[131072:131200].reshape((128,1))\n",
        "    parameters[\"W2\"] = theta[131200:132480].reshape((10, 128))\n",
        "    parameters[\"b2\"] = theta[132480:132490].reshape((10,1))\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "55_5yUJyBv0A"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    \n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "lq8eHQEVBv0A"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "   \n",
        "    s = np.maximum(0,x)\n",
        "    return s "
      ],
      "metadata": {
        "id": "kgF5a9d7Bv0B"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation_n(X, Y, parameters):\n",
        "  \n",
        "    \n",
        "\n",
        "    \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "\n",
        "    X=X.flatten()\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        " \n",
        "    output = np.dot(W2, A1) + b2\n",
        "    cost=cross_entropy_loss(Y,output)\n",
        "    \n",
        "\n",
        "    \n",
        "    return cost"
      ],
      "metadata": {
        "id": "DN_fdMESBv0B"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "parameters_values= dictionary_to_vector(model)"
      ],
      "metadata": {
        "id": "-GX2QXMLBv0B"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model.parameters())"
      ],
      "metadata": {
        "id": "ps8Zf8fPBv0B"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae521a42-286b-460b-c2f7-f1e191f12a83",
        "id": "hR5q7TXABv0B"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Net(\n",
              "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in params:\n",
        "  #print(param.data)\n",
        "  print(param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c389018-c859-4f23-fc9b-c0c3ecdd6b9a",
        "id": "c9mEeICBBv0C"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1024])\n",
            "torch.Size([128])\n",
            "torch.Size([10, 128])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def gradient_check_n(model, X, Y, epsilon=1e-7):\n",
        "   \n",
        "    warnings.filterwarnings('ignore')  \n",
        "    parameters_values = dictionary_to_vector(model)\n",
        "    grad = gradients_to_vector(model)\n",
        "    num_parameters = parameters_values.shape[0]\n",
        "    J_plus = np.zeros((num_parameters, 1))\n",
        "    J_minus = np.zeros((num_parameters, 1))\n",
        "    gradapprox = np.zeros((num_parameters, 1))\n",
        "    scaling=1                                                                                                                                                                                                                                                                                                                                        *.0000001\n",
        "    \n",
        "   \n",
        "    for i in range(num_parameters):\n",
        "        \n",
        "        \n",
        "        thetaplus =  np.copy(parameters_values)                                       # Step 1\n",
        "        thetaplus[i][0] = thetaplus[i][0] + epsilon                                   # Step 2\n",
        "        J_plus[i] =  forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))  # Step 3\n",
        "        \n",
        "    \n",
        "        thetaminus = np.copy(parameters_values)                                       # Step 1\n",
        "        thetaminus[i][0] = thetaminus[i][0] - epsilon                                 # Step 2        \n",
        "        J_minus[i] = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus)) # Step 3\n",
        "     \n",
        "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
        "      \n",
        " \n",
        "    numerator = np.linalg.norm(grad - gradapprox)                                     # Step 1'\n",
        "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   # Step 2'\n",
        "    difference = numerator / denominator \n",
        "    difference = difference*scaling                                              # Step 3'\n",
        "                                                                                                                                                                           \n",
        "    truth=0\n",
        "    if difference > 1e-7:\n",
        "        truth=1\n",
        "    \n",
        "    return truth"
      ],
      "metadata": {
        "id": "x2iH-7iIBv0C"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for data, target in train_dataset:\n",
        "  if i != 2 :\n",
        "\n",
        "        print(\"F\")\n",
        "        \n",
        "  \n",
        "        i=i+1\n",
        "  else :\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e359a5f0-2f30-43d6-8b7e-d79271c52cab",
        "id": "fKrJoQMSBv0C"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89a61dc-f02d-46e6-f138-fc7cdb342941",
        "id": "nNlLrwIcBv0C"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.numpy()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85959cf-69de-445e-8e99-764d973778c9",
        "id": "0MAFdv0HBv0C"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 0., ..., 1., 1., 1.],\n",
              "        [1., 0., 0., ..., 1., 1., 1.],\n",
              "        [0., 0., 0., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_check_n(model, data, target, 1e-7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d0c4c3-8e0a-47f4-f42c-be8c1be73b3b",
        "id": "W5jS-UepBv0C"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "zqlTqfmCBv0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1614a9a-a9e1-49ea-fd49-10de86dc1b53",
        "id": "EEjA6fOMBv0D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132490"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dictionary_to_vector(model):\n",
        "    \"\"\"\n",
        "    Roll all our parameters dictionary into a single vector satisfying our specific required shape.\n",
        "    \"\"\"\n",
        "    #keys = []\n",
        "    params = list(model.parameters())\n",
        "    p=[]\n",
        "    for param in params:\n",
        "      p.append(param.cpu().detach().numpy())\n",
        "     \n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(p)):\n",
        "  \n",
        "        \n",
        "        # flatten parameter\n",
        "        new_vector = np.reshape(p[i], (-1,1))\n",
        "        #keys = keys + [key]*new_vector.shape[0]\n",
        "        \n",
        "        if count == 0:\n",
        "            theta = new_vector\n",
        "        else:\n",
        "            theta = np.concatenate((theta, new_vector), axis=0)\n",
        "        count = count + 1\n",
        "\n",
        "    return theta"
      ],
      "metadata": {
        "id": "sAWESj3Tm4WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradients_to_vector(model):\n",
        "    \n",
        "    theta = np.reshape(model.fc1.weight.grad.cpu().detach().numpy(), (-1,1))\n",
        "    theta1=np.concatenate((theta,np.reshape( model.fc1.bias.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "    theta2=np.concatenate((theta1, np.reshape(model.fc2.weight.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "    theta3=np.concatenate((theta2, np.reshape(model.fc2.bias.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "\n",
        "    return theta3"
      ],
      "metadata": {
        "id": "yd1fLsxNlsir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_to_dictionary(theta):\n",
        "  \n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = theta[:131072].reshape(128, 1024)\n",
        "    parameters[\"b1\"] = theta[131072:131200].reshape((128,1))\n",
        "    parameters[\"W2\"] = theta[131200:132480].reshape((10, 128))\n",
        "    parameters[\"b2\"] = theta[132480:132490].reshape((10,1))\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "bD86y1riscxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    \n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "WE9QRpEL0vAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    s = np.maximum(0,x)\n",
        "    return s "
      ],
      "metadata": {
        "id": "Au9l7UYSIXtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation_n(X, Y, parameters):\n",
        "  \n",
        "    \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "\n",
        "    X=X.flatten()\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        " \n",
        "    output = np.dot(W2, A1) + b2\n",
        "    cost=cross_entropy_loss(Y,output)\n",
        "    \n",
        "\n",
        "    \n",
        "    return cost"
      ],
      "metadata": {
        "id": "g-gpcE1puyWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "parameters_values= dictionary_to_vector(model)"
      ],
      "metadata": {
        "id": "QNLq2njKjU7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model.parameters())"
      ],
      "metadata": {
        "id": "M9cVTicNiHPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLxla52SixWm",
        "outputId": "3a59fabd-b4c6-42ce-bffe-f130c612faa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Net(\n",
              "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in params:\n",
        "  #print(param.data)\n",
        "  print(param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yudMAtAjikLk",
        "outputId": "f42d46ea-4734-4f05-9e05-69adb6943688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1024])\n",
            "torch.Size([128])\n",
            "torch.Size([10, 128])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_check(model, X, Y, epsilon=1e-7):\n",
        " \n",
        "    parameters_values = dictionary_to_vector(model)\n",
        "    grad = gradients_to_vector(model)\n",
        "    num_parameters = parameters_values.shape[0]\n",
        "    J_plus = np.zeros((num_parameters, 1))\n",
        "    J_minus = np.zeros((num_parameters, 1))\n",
        "    scaling_fac=.0000001\n",
        "    gradapprox = np.zeros((num_parameters, 1))\n",
        "    for i in range(num_parameters):\n",
        "      \n",
        "        thetaplus =  np.copy(parameters_values)                                      \n",
        "        thetaplus[i][0] = thetaplus[i][0] + epsilon                                   \n",
        "        J_plus[i] =  forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))  \n",
        "       \n",
        "        thetaminus = np.copy(parameters_values)                                       \n",
        "        thetaminus[i][0] = thetaminus[i][0] - epsilon                                     \n",
        "        J_minus[i] = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus))\n",
        "       \n",
        "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
        "        \n",
        "    numerator = np.linalg.norm(grad - gradapprox)                                    \n",
        "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                  \n",
        "    difference = numerator / denominator \n",
        "    difference = difference*scaling_fac                                             \n",
        "  \n",
        "\n",
        "    if difference > 1e-7:\n",
        "        print(\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
        "    else:\n",
        "        print(\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
        "    \n",
        "    return difference"
      ],
      "metadata": {
        "id": "1xELXSWMar9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for data, target in train_dataset:\n",
        "  if i != 2 :\n",
        "\n",
        "        print(\"F\")\n",
        "        \n",
        "  \n",
        "        i=i+1\n",
        "  else :\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B8fvbKgpIfk",
        "outputId": "fce11c92-ebd8-47ca-c3a1-5ca90faca456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTpoh6GK2n83",
        "outputId": "6f57cc15-43ce-41a9-e338-7d257b61485f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.numpy()\n",
        "data"
      ],
      "metadata": {
        "id": "NTqG3LP4wScO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_check(model, data, target, 1e-7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7nns2vH2xdU",
        "outputId": "91bf3a07-f4fd-437b-ea26-92ab1fea32af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mYour backward propagation works perfectly fine! difference = 9.996481073745762e-08\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.996481073745762e-08"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=1,\n",
        "    classes=10,\n",
        "    batch_size=4,\n",
        "    learning_rate=0.001,\n",
        "    regularization=.001)"
      ],
      "metadata": {
        "id": "qRexlOBRCcfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "5059eb8101334d0182bb3fb192a5b513",
            "f49cde53bd0741d7bc37a9831023ef00",
            "888a43014ce54db18f02dd6685b78d4d",
            "f4f1725d3189415984a3ce81f223ad03",
            "661a1e65b16b4412bec5db7127ed92b5",
            "8af8e11426a14212a27522ba9b56ca7e",
            "23c67c27a1d24bcfbf8117e5dd314541",
            "5c1ad971ae274eaa912b96bf380bcd0a"
          ]
        },
        "id": "karFVFDb_h1G",
        "outputId": "b6f8ca78-6f45-49f0-ecfa-834ed1c25690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.094892…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5059eb8101334d0182bb3fb192a5b513"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▅▃▄▃▂▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.21785</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lambent-paper-4</strong> at: <a href=\"https://wandb.ai/sharma-87/gurnumL1/runs/0gbb0w2x\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL1/runs/0gbb0w2x</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230129_194414-0gbb0w2x/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "SdPBwq0EMWCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlyqRR-yMYZ5",
        "outputId": "c1614a9a-a9e1-49ea-fd49-10de86dc1b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132490"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bfAcS_qTlDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HApCqt4nTpoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L2\n",
        "\n"
      ],
      "metadata": {
        "id": "eUq4ny2_T0Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa12a932-11bd-44b9-8cb0-d3ee22c42fb1",
        "id": "OU3HW-dLT0Xn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.img_paths = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for label in os.listdir(root_dir):\n",
        "            label_dir = os.path.join(root_dir, label)\n",
        "            if not os.path.isdir(label_dir):\n",
        "                continue\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                self.img_paths.append(img_path)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = int(self.labels[idx])\n",
        "        return img, label\n",
        "\n"
      ],
      "metadata": {
        "id": "MNXWb1pOT0Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5aa2c9c-8c40-4ea2-f04b-96ab08bf53ea",
        "id": "LF7Lj2tkT0Xo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be87642-f305-4441-98d1-3134cb44bb3d",
        "id": "SaySxwh9T0Xo"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"gurnumL2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "a7f7da6d-54ed-4c98-8c12-82efb16436b2",
        "id": "gPW5j3SRT0Xo"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:vsgqhr30) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁██████████</td></tr><tr><td>loss</td><td>▆█▅▄▂▂▃▂▁▁▁▂▂▃▂▁▁▆▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.03709</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">festive-rabbit-6</strong> at: <a href=\"https://wandb.ai/sharma-87/gurnumL1/runs/vsgqhr30\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL1/runs/vsgqhr30</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_135850-vsgqhr30/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:vsgqhr30). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_142932-jajoox30</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/gurnumL2/runs/jajoox30\" target=\"_blank\">flashing-chrysanthemum-2</a></strong> to <a href=\"https://wandb.ai/sharma-87/gurnumL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/gurnumL2\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/gurnumL2/runs/jajoox30\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL2/runs/jajoox30</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/gurnumL2/runs/jajoox30?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0cef8bfa0>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WY4ATeDKT0Xo"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                ])\n",
        "\n",
        "train_dataset = ImageDataset(root_dir='/content/drive/MyDrive/GurNum/train', transform=transform)\n",
        "test_dataset = ImageDataset(root_dir='/content/drive/MyDrive/GurNum/val', transform=transform)\n"
      ],
      "metadata": {
        "id": "7oSxlwmWT0Xo"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "xLN67bx9T0Xo"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_dataset):\n",
        "    inputs, labels = data\n",
        "    print(data)\n",
        "    \n",
        "    if i == 2: # only show the first 3 data points\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e4af97-c5c6-4fa8-c17e-b56734325de6",
        "id": "XQW18CgwT0Xo"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n",
            "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n",
            "(tensor([[[1., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        # self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=1*32*32, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1NGucnjfT0Xo"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "VA46SuwMT0Xo"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9c3a76-9f42-448b-ae4f-1f66151adbc8",
        "id": "ULEqMvXrT0Xp"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "Fkqt9WvTT0Xp"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_loss(model, weight_decay):\n",
        "    l2_loss = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'bias' not in name:\n",
        "            l2_loss += torch.sum(torch.sum(param ** 2))\n",
        "    return weight_decay * l2_loss"
      ],
      "metadata": {
        "id": "Ra5rzgHhT0Xp"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "        if 'bias' not in name:\n",
        "            print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFOID8uQJwJZ",
        "outputId": "8f0cb1eb-b9e2-4ce3-9aaf-09e096e349f0"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0088, -0.0212, -0.0191,  ..., -0.0236, -0.0124, -0.0120],\n",
            "        [ 0.0126, -0.0299,  0.0168,  ...,  0.0134,  0.0139,  0.0099],\n",
            "        [ 0.0036,  0.0106, -0.0140,  ...,  0.0202, -0.0072, -0.0042],\n",
            "        ...,\n",
            "        [ 0.0222,  0.0262,  0.0093,  ..., -0.0274, -0.0006,  0.0089],\n",
            "        [-0.0159,  0.0137, -0.0175,  ...,  0.0136,  0.0052,  0.0258],\n",
            "        [-0.0260, -0.0063,  0.0036,  ..., -0.0193, -0.0174, -0.0301]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0631,  0.0671, -0.0301,  ...,  0.0093,  0.0180, -0.0625],\n",
            "        [-0.0347,  0.0425, -0.0413,  ...,  0.0570,  0.0804,  0.0863],\n",
            "        [ 0.0276,  0.0643,  0.0154,  ...,  0.0406, -0.0812,  0.0188],\n",
            "        ...,\n",
            "        [-0.0274,  0.0562, -0.0737,  ..., -0.0617, -0.0504,  0.0271],\n",
            "        [ 0.0580,  0.0339, -0.0799,  ...,  0.0824,  0.0474, -0.0520],\n",
            "        [ 0.0674,  0.0778,  0.0162,  ...,  0.0535, -0.0605,  0.0769]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".1 , 5"
      ],
      "metadata": {
        "id": "2c6LZeNOT0Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        target=torch.tensor(target)\n",
        "        reg_loss = l2_loss(model, 0.0000001)\n",
        "        loss = criterion(output, target.to(device)) +reg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n",
        "    print(\"for epoch \",epoch, \" loss= \",running_loss)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abd1968-d6bb-4190-9f74-e418b4f643d2",
        "id": "H4OncV4HT0Xp"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00096 examples: 2.206\n",
            "Loss after 00196 examples: 1.496\n",
            "Loss after 00296 examples: 0.823\n",
            "Loss after 00396 examples: 0.949\n",
            "Loss after 00496 examples: 0.421\n",
            "Loss after 00596 examples: 0.295\n",
            "Loss after 00696 examples: 0.399\n",
            "Loss after 00796 examples: 0.060\n",
            "Loss after 00896 examples: 0.099\n",
            "Loss after 00996 examples: 0.272\n",
            "for epoch  0  loss=  218.5984680056572\n",
            "Loss after 01096 examples: 0.239\n",
            "Loss after 01196 examples: 0.026\n",
            "Loss after 01296 examples: 0.055\n",
            "Loss after 01396 examples: 0.514\n",
            "Loss after 01496 examples: 0.023\n",
            "Loss after 01596 examples: 0.249\n",
            "Loss after 01696 examples: 0.149\n",
            "Loss after 01796 examples: 0.486\n",
            "Loss after 01896 examples: 0.043\n",
            "Loss after 01996 examples: 0.077\n",
            "for epoch  1  loss=  51.35153544135392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data=data.to(device)\n",
        "            target=target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    #wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bc40c2-ffd3-4147-dd39-90ed915d60ba",
        "id": "PIj0PeyYT0Xp"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 91.57303370786516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# l2 grad\n"
      ],
      "metadata": {
        "id": "Xpm2NhWYaCqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dictionary_to_vector(model):\n",
        "    \"\"\"\n",
        "    Roll all our parameters dictionary into a single vector satisfying our specific required shape.\n",
        "    \"\"\"\n",
        "    #keys = []\n",
        "    params = list(model.parameters())\n",
        "    p=[]\n",
        "    for param in params:\n",
        "      p.append(param.cpu().detach().numpy())\n",
        "     \n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(p)):\n",
        "  \n",
        "        \n",
        "        # flatten parameter\n",
        "        new_vector = np.reshape(p[i], (-1,1))\n",
        "        #keys = keys + [key]*new_vector.shape[0]\n",
        "        \n",
        "        if count == 0:\n",
        "            theta = new_vector\n",
        "        else:\n",
        "            theta = np.concatenate((theta, new_vector), axis=0)\n",
        "        count = count + 1\n",
        "\n",
        "    return theta"
      ],
      "metadata": {
        "id": "GFz_D-kIaWc1"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradients_to_vector(model):\n",
        "    \n",
        "    theta = np.reshape(model.fc1.weight.grad.cpu().detach().numpy(), (-1,1))\n",
        "    theta1=np.concatenate((theta,np.reshape( model.fc1.bias.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "    theta2=np.concatenate((theta1, np.reshape(model.fc2.weight.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "    theta3=np.concatenate((theta2, np.reshape(model.fc2.bias.grad.cpu().detach().numpy(), (-1,1))), axis=0)\n",
        "\n",
        "    return theta3"
      ],
      "metadata": {
        "id": "UcIIFeILaWc1"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_to_dictionary(theta):\n",
        "    \"\"\"\n",
        "    Unroll all our parameters dictionary from a single vector satisfying our specific required shape.\n",
        "    \"\"\"\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = theta[:131072].reshape(128, 1024)\n",
        "    parameters[\"b1\"] = theta[131072:131200].reshape((128,1))\n",
        "    parameters[\"W2\"] = theta[131200:132480].reshape((10, 128))\n",
        "    parameters[\"b2\"] = theta[132480:132490].reshape((10,1))\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "l-Nr7aMAaWc1"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    \n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "OFBcF_DIaWc2"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  \n",
        "    s = np.maximum(0,x)\n",
        "    return s "
      ],
      "metadata": {
        "id": "3AhRNBFxaWc2"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation_n(X, Y, parameters):\n",
        "  \n",
        "    \n",
        " \n",
        "    \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "\n",
        "    X=X.flatten()\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        " \n",
        "    output = np.dot(W2, A1) + b2\n",
        "    cost=cross_entropy_loss(Y,output)\n",
        "    \n",
        "\n",
        "    \n",
        "    return cost"
      ],
      "metadata": {
        "id": "nUglM96faWc2"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "parameters_values= dictionary_to_vector(model)"
      ],
      "metadata": {
        "id": "lsQZ6GUTaWc2"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model.parameters())"
      ],
      "metadata": {
        "id": "j3FYlNKvaWc2"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9436c95-9802-40be-d624-761365ee1aac",
        "id": "nML2cTQVaWc2"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Net(\n",
              "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in params:\n",
        "  #print(param.data)\n",
        "  print(param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aadcdbd-7182-4fd3-bec7-fde51706c3de",
        "id": "eGy216t4aWc2"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1024])\n",
            "torch.Size([128])\n",
            "torch.Size([10, 128])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def gradient_check_n(model, X, Y, epsilon=1e-7):\n",
        "\n",
        "   \n",
        "    parameters_values = dictionary_to_vector(model)\n",
        "    grad = gradients_to_vector(model)\n",
        "    num_parameters = parameters_values.shape[0]\n",
        "    J_plus = np.zeros((num_parameters, 1))\n",
        "    J_minus = np.zeros((num_parameters, 1))\n",
        "    gradapprox = np.zeros((num_parameters, 1))\n",
        "    \n",
        "    \n",
        "    for i in range(num_parameters):\n",
        "        \n",
        "        \n",
        "        thetaplus =  np.copy(parameters_values)                                       # Step 1\n",
        "        thetaplus[i][0] = thetaplus[i][0] + epsilon                                   # Step 2\n",
        "        J_plus[i] =  forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))  # Step 3\n",
        "        \n",
        "        thetaminus = np.copy(parameters_values)                                       # Step 1\n",
        "        thetaminus[i][0] = thetaminus[i][0] - epsilon                                 # Step 2        \n",
        "        J_minus[i] = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus)) # Step 3\n",
        "        \n",
        "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
        "       \n",
        "    \n",
        "    \n",
        "    numerator = np.linalg.norm(grad - gradapprox)                                     # Step 1'\n",
        "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   # Step 2'\n",
        "    difference = numerator / denominator                                              # Step 3'\n",
        "    \n",
        "    truth=0\n",
        "    if difference > 1e-7:\n",
        "        truth=1\n",
        "        print(difference)\n",
        "   \n",
        "    return truth"
      ],
      "metadata": {
        "id": "gOFCBhOIaWc2"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for data, target in train_dataset:\n",
        "  if i != 2 :\n",
        "\n",
        "        print(\"F\")\n",
        "        \n",
        "  \n",
        "        i=i+1\n",
        "  else :\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5069931-58a6-4f6a-adad-0a744783926c",
        "id": "nqu4nxBTaWc2"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0782a210-c377-42ed-8816-e9e75c125ebe",
        "id": "6nqdE1nPaWc2"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.numpy()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6267c7-b1c3-4dba-d585-8c728b55bfea",
        "id": "o_DKs0BlaWc2"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 0., ..., 1., 1., 1.],\n",
              "        [1., 0., 0., ..., 1., 1., 1.],\n",
              "        [0., 0., 0., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_check_n(model, data, target, 1e-7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3e4f40-03e4-4a74-a9da-055d89976466",
        "id": "JI2rrTWyaWc2"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9993981630496983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "oceZLpAVaWc3"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(model)"
      ],
      "metadata": {
        "id": "nPmePuqQaWc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9b5c7b-1c89-47bd-e1fa-07443bd74a2b"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132490"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HF-sDQqLcQo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f313cfe-10e6-4ad4-b733-43dd92ebf276",
        "id": "9X8PcLUScQo6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.img_paths = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for label in os.listdir(root_dir):\n",
        "            label_dir = os.path.join(root_dir, label)\n",
        "            if not os.path.isdir(label_dir):\n",
        "                continue\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                self.img_paths.append(img_path)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = int(self.labels[idx])\n",
        "        return img, label\n",
        "\n"
      ],
      "metadata": {
        "id": "Vu0hw73lcQo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -Uq"
      ],
      "metadata": {
        "id": "Nyey1U_AcQo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d4ec2c-5e0e-48a2-8659-b4983e8581ec",
        "id": "AtB5WCjYcQo7"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"gurnum_drop_out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "d67e4130b3a1445b8d272164d7b9a477",
            "14df141ee3b040108151d43d1396ce5f",
            "255db6b71f2b4fa4a8be0ffffc9c180b",
            "fbf99131b7cc4ece921edf9c3b8663bb",
            "7f06edaa25f64c22b5dc1fefb296f157",
            "13ac30958b0e444ba1452c6df9b83ce9",
            "4b60603ff754468585ddd3ee742df32b",
            "96d8bab3aaae4335bbc5d70671ac0d11"
          ]
        },
        "outputId": "b33b7deb-fdb0-4053-fc8f-47bd5e578150",
        "id": "M4UyJnh8cQo7"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:jajoox30) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d67e4130b3a1445b8d272164d7b9a477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁██████████</td></tr><tr><td>loss</td><td>█▆▄▄▂▂▂▁▁▂▂▁▁▃▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.07651</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">flashing-chrysanthemum-2</strong> at: <a href=\"https://wandb.ai/sharma-87/gurnumL2/runs/jajoox30\" target=\"_blank\">https://wandb.ai/sharma-87/gurnumL2/runs/jajoox30</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_142932-jajoox30/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:jajoox30). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_150235-c2zxb6ck</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sharma-87/gurnum_drop_out/runs/c2zxb6ck\" target=\"_blank\">enchanting-paper-4</a></strong> to <a href=\"https://wandb.ai/sharma-87/gurnum_drop_out\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sharma-87/gurnum_drop_out\" target=\"_blank\">https://wandb.ai/sharma-87/gurnum_drop_out</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sharma-87/gurnum_drop_out/runs/c2zxb6ck\" target=\"_blank\">https://wandb.ai/sharma-87/gurnum_drop_out/runs/c2zxb6ck</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sharma-87/gurnum_drop_out/runs/c2zxb6ck?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0cef19250>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Xei_iuzncQo7"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                ])\n",
        "\n",
        "train_dataset = ImageDataset(root_dir='/content/drive/MyDrive/GurNum/train', transform=transform)\n",
        "test_dataset = ImageDataset(root_dir='/content/drive/MyDrive/GurNum/val', transform=transform)\n"
      ],
      "metadata": {
        "id": "fP1skb0jcQo7"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "qQZG9XrhcQo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_dataset):\n",
        "    inputs, labels = data\n",
        "    print(data)\n",
        "    \n",
        "    if i == 2: # only show the first 3 data points\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9cf238-bc3c-4abf-b8a2-e1782b304c57",
        "id": "B3YMMt7GcQo7"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n",
            "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n",
            "(tensor([[[1., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]]), 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        # self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=1*32*32, out_features=128)\n",
        "        self.dropout = nn.Dropout(0.12)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CkzLBtB_cQo7"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "t4VtT4vYcQo8"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e47948e-128c-44e4-9128-0999f0df875f",
        "id": "HFbge4zecQo8"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "MmyBSktScQo8"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_ct = 0  # number of examples seen\n",
        "batch_ct = 0\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(device))\n",
        "        target=torch.tensor(target)\n",
        "        loss = criterion(output, target.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        example_ct +=  len(target)\n",
        "        batch_ct += 1\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "        running_loss += loss.item()\n",
        "    print(\"for epoch \",epoch, \" loss= \",running_loss)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2dc5531-1fcb-4f0c-bc24-81d635dc5669",
        "id": "ffNtFZwLcQo8"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00096 examples: 0.035\n",
            "Loss after 00196 examples: 0.085\n",
            "Loss after 00296 examples: 0.038\n",
            "Loss after 00396 examples: 0.019\n",
            "Loss after 00496 examples: 0.018\n",
            "Loss after 00596 examples: 0.297\n",
            "Loss after 00696 examples: 0.049\n",
            "Loss after 00796 examples: 0.030\n",
            "Loss after 00896 examples: 1.025\n",
            "Loss after 00996 examples: 0.049\n",
            "for epoch  0  loss=  34.72037482727319\n",
            "Loss after 01096 examples: 0.573\n",
            "Loss after 01196 examples: 0.011\n",
            "Loss after 01296 examples: 0.044\n",
            "Loss after 01396 examples: 0.177\n",
            "Loss after 01496 examples: 0.027\n",
            "Loss after 01596 examples: 0.055\n",
            "Loss after 01696 examples: 0.099\n",
            "Loss after 01796 examples: 0.004\n",
            "Loss after 01896 examples: 0.378\n",
            "Loss after 01996 examples: 0.019\n",
            "for epoch  1  loss=  23.10290250205435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data=data.to(device)\n",
        "            target=target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    #wandb.log({\"test_accuracy\": correct / total})\n",
        "    return accuracy\n",
        "\n",
        "print(\"Model accuracy:\", evaluate_model(model, test_loader))\n",
        "acc=evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214450ee-e11d-4165-b83e-d721ab610457",
        "id": "g7J-Qx9scQo8"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 92.69662921348315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({\"accuracy\": acc})"
      ],
      "metadata": {
        "id": "xyisSOEXcQo8"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "5-46Exr-d2BJ",
        "outputId": "25cda2df-41a0-4d69-8c1f-c278e99cf1c0"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁██████████</td></tr><tr><td>loss</td><td>██▄▄▂▂▄▂▁▃▁▂▁▂▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>92.13483</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.01861</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">enchanting-paper-4</strong> at: <a href=\"https://wandb.ai/sharma-87/gurnum_drop_out/runs/c2zxb6ck\" target=\"_blank\">https://wandb.ai/sharma-87/gurnum_drop_out/runs/c2zxb6ck</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230130_150235-c2zxb6ck/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47juLEFRb2_x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}